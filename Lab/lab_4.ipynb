{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d987d1af",
   "metadata": {},
   "source": [
    "Submission Guideline\n",
    "* Do not clear your outputs. This notebook will not have autograder, we will not download and run your solution.\n",
    "* You will have till 11.59 pm tonight to finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "261f97b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593ce039",
   "metadata": {},
   "source": [
    "# Why do we offload computations to GPU?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "98f627a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_matrix_a = torch.randn(10000,20000)\n",
    "random_matrix_b = torch.randn(20000,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c8827aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 10000])\n",
      "16.9 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "#CPU version\n",
    "out = torch.matmul(random_matrix_a, random_matrix_b)\n",
    "# out = random_matrix_a @ random_matrix_b\n",
    "# out = torch.einsum('ij,jk->ik', random_matrix_a, random_matrix_b)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "83488347",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Move to GPU\n",
    "random_matrix_a = random_matrix_a.to(device)\n",
    "random_matrix_b = random_matrix_b.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9c14938e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 10000])\n",
      "230 μs ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "#CPU version\n",
    "out = torch.matmul(random_matrix_a, random_matrix_b)\n",
    "# out = random_matrix_a @ random_matrix_b\n",
    "# out = torch.einsum('ij,jk->ik', random_matrix_a, random_matrix_b)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f35f460e",
   "metadata": {},
   "outputs": [],
   "source": [
    "del random_matrix_a, random_matrix_b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4f2aec",
   "metadata": {},
   "source": [
    "### 1) Use `%%timeit` to compare performance of the [inverse](https://docs.pytorch.org/docs/stable/generated/torch.inverse.html) and [mean](https://docs.pytorch.org/docs/stable/generated/torch.mean.html) function on CPU and GPU. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a8be156d",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_matrix_inv = torch.randn(10000,10000) # create a random square matrix\n",
    "random_matrix_mean = torch.randn(5,20000) # Compute Mean across rows (5,20000) -> (20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "99c934e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "torch.Size([10000, 10000])\n",
      "11.8 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "#CPU Inverse\n",
    "print(random_matrix_inv.device)\n",
    "out = torch.inverse(random_matrix_inv)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "18143f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move random_matrix_inv to GPU\n",
    "random_matrix_inv = random_matrix_inv.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ec8f796b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 10000])\n",
      "137 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "#GPU Inverse\n",
    "out = torch.inverse(random_matrix_inv)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9bff60c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0029)\n",
      "20.2 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "#CPU Mean\n",
    "out = torch.mean(random_matrix_mean)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0eef9a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Move random_matrix_mean to GPU\n",
    "random_matrix_mean = random_matrix_mean.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4a14248a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0029, device='cuda:0')\n",
      "542 μs ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "#GPU Mean\n",
    "out = torch.mean(random_matrix_mean)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fef809a",
   "metadata": {},
   "source": [
    "### 2) Complete the following code-blocks to generate a classifier for predicting 1000 classes.\n",
    "\n",
    "Assume you have input features $\\in R^{512}$, Complete the shapes of weight matrices and einsum strings so that the number of features is [1024,2048,1000] for your three layer network with no bias and relu activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5f85000c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1024, 512])\n"
     ]
    }
   ],
   "source": [
    "input_features = torch.randn(64,1024,512) # batch size of 64, 1024 pixels, 512 features\n",
    "print(input_features.shape)\n",
    "weight_1 = torch.randn(512,1024)\n",
    "weight_2 = torch.randn(1024,2048)\n",
    "weight_3 = torch.randn(2048,1000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "20731d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1000])\n"
     ]
    }
   ],
   "source": [
    "layer_1 = torch.einsum('bnd,dh->bnh', input_features, weight_1)\n",
    "layer_1 = torch.relu(layer_1) # Suppress Negative Values\n",
    "layer_2 = torch.einsum('bnh,hm->bnm', layer_1, weight_2)\n",
    "layer_2 = torch.relu(layer_2) # Suppress Negative Values\n",
    "output = torch.einsum('bnm,mq->bnq', layer_2, weight_3)\n",
    "output = torch.mean(output,1) # Average All Pixels (64,1024,1000) -> (64,1000), dim=1 means '1024' dimension\n",
    "# output = torch.einsum('bnq->bq',output) / output.shape[1]\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efadd0a4-c668-494c-b9b0-af6c3638b139",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
